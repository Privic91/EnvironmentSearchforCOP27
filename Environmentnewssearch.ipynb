{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import csv\n",
    "URL = \"https://economictimes.indiatimes.com/topic/environment-and-natural-resources\"\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "results = soup.find_all('div',class_=\"contentD\")\n",
    "\n",
    "\n",
    "data = []\n",
    "v=[]\n",
    "\n",
    "for job_element in results:\n",
    "\n",
    "\n",
    "    python1 = job_element.find('h2')\n",
    "\n",
    "    data.append(python1.string)\n",
    "for job_element in results:\n",
    "\n",
    "\n",
    "    python2 = job_element.find('time')\n",
    "\n",
    "    v.append(python2.string)\n",
    "df = pd.DataFrame({\"Data\": data,\"Date\":v})\n",
    "\n",
    "\n",
    "\n",
    "b = df[df['Data'].str.contains(\"COP27\")] \n",
    "\n",
    "\n",
    "b.to_csv(\"India.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import csv\n",
    "URL = \"https://www.mse.gov.sg/news/\"\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "data=[]\n",
    "\n",
    "results = soup.find_all('div',class_='media-card-plain bg-media-color-5 padding--lg')\n",
    "results\n",
    "\n",
    "\n",
    "\n",
    "for job_element in results:\n",
    "\n",
    "\n",
    "    python1 = job_element.find('h5')\n",
    "\n",
    "    data.append(python1.string)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"Data\": data})\n",
    "\n",
    "df=df[1:40]\n",
    "#df\n",
    "#a = df[df['Data'].str.contains(\"China\")]\n",
    "\n",
    "b = df[df['Data'].str.contains(\"COP27\")]\n",
    "\n",
    "#df = a | b\n",
    "#a.to_csv('Singapore.csv')\n",
    "b.to_csv('SIngapore.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "element_list = []\n",
    "for page in range(1, 20, 5):\n",
    "    URL = \"https://eng.me.go.kr/eng/web/board/list.do?maxPageItems=6&maxIndexPages=10&searchKey=&searchValue=&boardMasterId=523&menuId=460&boardCategoryId=3&condition.hideCate=&condition.createDeptCode=&condition.createDeptName=&condition.fromDate=&condition.toDate=&condition.order=&condition.createId=&decorator=&condition.proxyParam1=&condition.proxyParam2=&condition.proxyParam3=&proxyListPath=&proxyReadPath=&pagerOffset=\" + str(page)\n",
    "\n",
    "    req = requests.get(URL)\n",
    "    soup = bs(req.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    titles = soup.find_all('div',class_='txt')\n",
    "    \n",
    "   \n",
    "\n",
    "    for i in range(len(titles)):\n",
    "        element_list.append([titles[i].text])\n",
    "        \n",
    "#print(\"element_list\")\n",
    "\n",
    "df = pd.DataFrame({\"Element_list\": element_list})\n",
    "\n",
    "\n",
    "df.to_csv(\"Korea1.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Korea1.csv\")\n",
    "df.replace('u\\n','')\n",
    "a= df[df['Element_list'].str.contains('COP27')]\n",
    "a.to_csv(\"korea.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bs4\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "element_list = []\n",
    "data=[]\n",
    "for page in range(1,30, 5):\n",
    "    URL = \"https://www.denr.gov.ph/index.php/news-events/press-releases?start=\" + str(page)\n",
    "    \n",
    "\n",
    "\n",
    "    req = requests.get(URL)\n",
    "    soup = bs(req.content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    titles = soup.find_all('div',class_=\"page-header\")\n",
    "    titles1 = soup.find_all(class_=\"published\")\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(len(titles)):\n",
    "        element_list.append([titles[i].text])\n",
    "        \n",
    "    for i in range(len(titles1)):\n",
    "        \n",
    "        \n",
    "\n",
    "        data.append([titles1[i].text])\n",
    " \n",
    "      \n",
    "        \n",
    "df = pd.DataFrame({\"Element_list\": element_list,\"time\":data})\n",
    "\n",
    "df.to_csv(\"PHILLI.csv\")\n",
    "\n",
    "df = pd.read_csv(\"PHILLI.csv\")\n",
    "df.replace('u\\n','')\n",
    "a= df[df['Element_list'].str.contains('COP27')]\n",
    "a.to_csv(\"phillipines.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bs4\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "element_list = []\n",
    "data=[]\n",
    "for pag in range(1,10, 10):\n",
    "    URL = \"https://vietnamnews.vn/environment?p=\" + str(pag)\n",
    "    \n",
    "    \n",
    "\n",
    "    req = requests.get(URL)\n",
    "    soup = bs(req.content, 'html.parser')\n",
    "    \n",
    "\n",
    "    titles = soup.find_all('a',class_=\"story__title\")\n",
    "    \n",
    "    \n",
    "    for i in range(len(titles)):\n",
    "        element_list.append([titles[i].text])\n",
    "        \n",
    "df = pd.DataFrame({\"Element_list\": element_list})\n",
    "df.align\n",
    "#df\n",
    "df.to_csv(\"Viet.csv\")\n",
    "\n",
    "\n",
    "#df = pd.read_csv(\"Viet.csv\")\n",
    "\n",
    "#a= df[df['Element_list'].str.contains('COP')]\n",
    "#df.to_csv(\"Vietnam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bs4\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "element_list = []\n",
    "data=[]\n",
    "for pag in range(2,10, 10):\n",
    "    URL = \"https://vietnamnews.vn/environment?p=\" + str(pag)\n",
    "    \n",
    "    \n",
    "\n",
    "    req = requests.get(URL)\n",
    "    soup = bs(req.content, 'html.parser')\n",
    "    \n",
    "\n",
    "    titles = soup.find_all('a',class_=\"story__title\")\n",
    "    \n",
    "    \n",
    "    for i in range(len(titles)):\n",
    "        element_list.append([titles[i].text])\n",
    "        \n",
    "df = pd.DataFrame({\"Element_list\": element_list})\n",
    "df.align\n",
    "#df\n",
    "df.to_csv(\"Vietn.csv\")\n",
    "\n",
    "\n",
    "\n",
    "#df.to_csv(\"Vietnam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Vietn.csv\")\n",
    "#df.replace('u\\n','')\n",
    "a= df[df['Element_list'].str.contains('COP27')]\n",
    "a.to_csv(\"Vietnam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Viet.csv\")\n",
    "#df.replace('u\\n','')\n",
    "a= df[df['Element_list'].str.contains('COP27')]\n",
    "a.to_csv(\"Vietnam1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bs4\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "element_list = []\n",
    "data=[]\n",
    "for pag in range(1,40, 40):\n",
    "    URL = \"https://thainews.prd.go.th/en/news/category/1/\" + str(pag)\n",
    "    req = requests.get(URL)\n",
    "    soup = bs(req.content, 'html.parser')\n",
    "    \n",
    "    titles = soup.find_all('div',class_=\"col-12 pl-2\")\n",
    "    \n",
    "    for i in range(len(titles)):\n",
    "        element_list.append([titles[i].text])\n",
    "        \n",
    "df = pd.DataFrame({\"Element_list\": element_list})\n",
    "df.to_csv(\"thai.csv\")\n",
    "df = pd.read_csv(\"thai.csv\")\n",
    "df.replace('u\\n','')\n",
    "a= df[df['Element_list'].str.contains('COP27')]\n",
    "a.to_csv(\"Thailand.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
